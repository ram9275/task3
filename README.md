# task3
ML model training I have learned that linear regression assumes a linear relationship between independent and dependent variables, with independence of errors, constant variance (homoscedasticity), and normally distributed residuals. The coefficients tell me how each feature influences the target variableâ€”positive values increase predictions, while negative values decrease them. The RÂ² score indicates how much variance my model explains; closer to 1 is better, but a low value suggests missing important predictors. MSE penalizes large errors more, making it useful when I want to minimize extreme mistakes, while MAE treats all errors equally. Multicollinearity, where features are highly correlated, can distort predictions, and I can detect it using a correlation matrix or Variance Inflation Factor (VIF). Simple regression uses one independent variable, while multiple regression includes two or more. I now understand that linear regression isnâ€™t ideal for classification, but logistic regression is better suited for such tasks. If I violate the model's assumptions, it can lead to biased coefficients, unreliable predictions, and misleading statistical significance, requiring transformations or alternative models for correction. ðŸš€ I feel confident in applying these concepts in real-world analysis!
